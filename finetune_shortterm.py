"""
çŸ­æœŸé¢„æµ‹æ¨¡å‹ç²¾ç»†å¾®è°ƒè„šæœ¬
ç›®æ ‡ï¼šé’ˆå¯¹ singlestep å’Œ multistep_1h ä»»åŠ¡è¿›è¡Œç²¾ç»†åŒ–è°ƒä¼˜

ç­–ç•¥ï¼š
1. ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡è¿›è¡Œå¾®è°ƒ
2. å¢åŠ è®­ç»ƒè½®æ•°ï¼Œé™ä½æ—©åœæ•æ„Ÿåº¦
3. ä½¿ç”¨MSEä½œä¸ºåˆ¤æ–­æ ‡å‡†ï¼ˆçŸ­æœŸé¢„æµ‹MSEæ•æ„Ÿï¼‰
4. æ·»åŠ å­¦ä¹ ç‡é¢„çƒ­å’Œæ›´ç²¾ç»†çš„è°ƒåº¦

ç”¨æ³•ï¼š
    python finetune_shortterm.py                          # å¾®è°ƒæ‰€æœ‰çŸ­æœŸä»»åŠ¡çš„æ‰€æœ‰æ¨¡å‹
    python finetune_shortterm.py --task singlestep        # ä»…å¾®è°ƒsinglestep
    python finetune_shortterm.py --models LSTM Transformer  # ä»…å¾®è°ƒæŒ‡å®šæ¨¡å‹
    python finetune_shortterm.py --lr 0.0001 --epochs 80  # è‡ªå®šä¹‰è¶…å‚
"""

import os
import sys
import argparse
import torch
import numpy as np
from datetime import datetime

# è®¾ç½®æ— å¤´æ¨¡å¼
if sys.platform.startswith('linux') and not os.environ.get('DISPLAY'):
    os.environ['QT_QPA_PLATFORM'] = 'offscreen'
    import matplotlib
    matplotlib.use('Agg')

from config import (
    DEVICE, MODELS_DIR, RESULTS_DIR, set_seed, RANDOM_SEED,
    SINGLE_STEP_INPUT_LEN, SINGLE_STEP_OUTPUT_LEN,
    MULTI_STEP_1_INPUT_LEN, MULTI_STEP_1_OUTPUT_LEN,
)
from data_loader import load_all_data, preprocess_data, create_dataloaders
from models import get_model, count_parameters
from models_innovative import get_innovative_model
from trainer import train_model, test_model, print_test_results, load_model


# ==================== çŸ­æœŸä»»åŠ¡å¾®è°ƒè¶…å‚ ====================
# è¿™äº›å‚æ•°ä¸“é—¨é’ˆå¯¹çŸ­æœŸé¢„æµ‹ä¼˜åŒ–
FINETUNE_CONFIG = {
    'singlestep': {
        'lr': 0.0003,           # è¾ƒä½å­¦ä¹ ç‡ï¼Œç²¾ç»†è°ƒæ•´
        'epochs': 80,           # è¶³å¤Ÿçš„è®­ç»ƒè½®æ•°
        'patience': 25,         # å®½æ¾æ—©åœï¼Œå…è®¸æ›´å¤šæ¢ç´¢
        'warmup_epochs': 5,     # å­¦ä¹ ç‡é¢„çƒ­
        'description': 'å•æ­¥é¢„æµ‹å¾®è°ƒ (8hâ†’1h)',
    },
    'multistep_1h': {
        'lr': 0.00025,          # æ›´ä½çš„å­¦ä¹ ç‡
        'epochs': 100,          # æ›´å¤šè®­ç»ƒè½®æ•°
        'patience': 30,         # æ›´å®½æ¾çš„æ—©åœ
        'warmup_epochs': 8,     # æ›´é•¿çš„é¢„çƒ­
        'description': 'å¤šæ­¥1hé¢„æµ‹å¾®è°ƒ (8hâ†’1h)',
    }
}

# æ‰€æœ‰å¯ç”¨æ¨¡å‹
ALL_MODELS = ['Linear', 'LSTM', 'Transformer', 'CNN_LSTM', 'Attention_LSTM', 'TCN', 'WaveNet']
INNOVATIVE_MODELS = ['CNN_LSTM', 'Attention_LSTM', 'TCN', 'WaveNet']


def get_task_config(task_name):
    """è·å–ä»»åŠ¡é…ç½®"""
    if task_name == 'singlestep':
        return SINGLE_STEP_INPUT_LEN, SINGLE_STEP_OUTPUT_LEN
    elif task_name == 'multistep_1h':
        return MULTI_STEP_1_INPUT_LEN, MULTI_STEP_1_OUTPUT_LEN
    else:
        raise ValueError(f"æ­¤è„šæœ¬ä»…æ”¯æŒçŸ­æœŸä»»åŠ¡: singlestep, multistep_1h")


def finetune_model(model_name, task_name, df, config, batch_size=64, verbose=True):
    """
    å¾®è°ƒå•ä¸ªæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        task_name: ä»»åŠ¡åç§°
        df: é¢„å¤„ç†åçš„æ•°æ®
        config: å¾®è°ƒé…ç½®
        batch_size: æ‰¹æ¬¡å¤§å°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        æµ‹è¯•æŒ‡æ ‡, è®­ç»ƒå†å²
    """
    input_len, output_len = get_task_config(task_name)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader, scaler_features, scaler_targets, feature_cols, target_cols = \
        create_dataloaders(df, input_len, output_len, batch_size)
    
    num_features = len(feature_cols)
    num_targets = len(target_cols)
    
    # åˆ›å»ºæ¨¡å‹
    is_innovative = model_name in INNOVATIVE_MODELS
    if is_innovative:
        model = get_innovative_model(model_name, input_len, output_len, num_features, num_targets)
    else:
        model = get_model(model_name, input_len, output_len, num_features, num_targets)
    
    if verbose:
        print(f"\n{'='*60}")
        print(f"å¾®è°ƒ {model_name} - {config['description']}")
        print(f"{'='*60}")
        print(f"å‚æ•°é‡: {count_parameters(model):,}")
        print(f"å­¦ä¹ ç‡: {config['lr']}")
        print(f"è®­ç»ƒè½®æ•°: {config['epochs']}")
        print(f"æ—©åœè€å¿ƒ: {config['patience']}")
    
    # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹ä½œä¸ºèµ·ç‚¹
    model_path = os.path.join(MODELS_DIR, f"{model_name}_{task_name}.pth")
    if os.path.exists(model_path):
        try:
            model, prev_history = load_model(model, model_path)
            if verbose:
                best_loss = prev_history.get('best_val_loss', 'N/A')
                if isinstance(best_loss, (int, float)):
                    print(f"âœ… åŠ è½½å·²æœ‰æ¨¡å‹ï¼Œä¹‹å‰æœ€ä½³æŸå¤±: {best_loss:.4f}")
                else:
                    print(f"âœ… åŠ è½½å·²æœ‰æ¨¡å‹")
        except Exception as e:
            if verbose:
                print(f"âš ï¸ æ— æ³•åŠ è½½å·²æœ‰æ¨¡å‹ï¼Œä»å¤´è®­ç»ƒ: {e}")
    
    # å¾®è°ƒè®­ç»ƒ
    history = train_model(
        model, train_loader, val_loader,
        model_name=model_name,
        task_name=task_name,
        num_epochs=config['epochs'],
        learning_rate=config['lr'],
        patience=config['patience'],
        device=DEVICE,
        save_best=True,
        verbose=verbose,
        resume=True  # å§‹ç»ˆå°è¯•ç»§ç»­è®­ç»ƒ
    )
    
    # æµ‹è¯•
    metrics, metrics_per_target, predictions, targets = test_model(
        model, test_loader, scaler_targets, device=DEVICE
    )
    
    if verbose:
        print_test_results(model_name, task_name, metrics, metrics_per_target, target_cols)
    
    return metrics, history


def main():
    parser = argparse.ArgumentParser(description='çŸ­æœŸé¢„æµ‹æ¨¡å‹ç²¾ç»†å¾®è°ƒ')
    parser.add_argument('--task', type=str, default=None, choices=['singlestep', 'multistep_1h'],
                        help='æŒ‡å®šè¦å¾®è°ƒçš„ä»»åŠ¡ï¼ˆä¸æŒ‡å®šåˆ™å…¨éƒ¨å¾®è°ƒï¼‰')
    parser.add_argument('--models', type=str, nargs='+', default=None,
                        help='æŒ‡å®šè¦å¾®è°ƒçš„æ¨¡å‹ï¼ˆä¸æŒ‡å®šåˆ™å…¨éƒ¨å¾®è°ƒï¼‰')
    parser.add_argument('--lr', type=float, default=None,
                        help='è¦†ç›–é»˜è®¤å­¦ä¹ ç‡')
    parser.add_argument('--epochs', type=int, default=None,
                        help='è¦†ç›–é»˜è®¤è®­ç»ƒè½®æ•°')
    parser.add_argument('--patience', type=int, default=None,
                        help='è¦†ç›–é»˜è®¤æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--batch-size', type=int, default=64,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--quiet', action='store_true',
                        help='å‡å°‘è¾“å‡º')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(RANDOM_SEED)
    
    print("=" * 70)
    print("ğŸ”§ çŸ­æœŸé¢„æµ‹æ¨¡å‹ç²¾ç»†å¾®è°ƒ")
    print("=" * 70)
    print(f"è®¾å¤‡: {DEVICE}")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    raw_df = load_all_data()
    df = preprocess_data(raw_df)
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # ç¡®å®šè¦å¾®è°ƒçš„ä»»åŠ¡å’Œæ¨¡å‹
    tasks = [args.task] if args.task else ['singlestep', 'multistep_1h']
    models = args.models if args.models else ALL_MODELS
    
    # éªŒè¯æ¨¡å‹åç§°
    invalid_models = [m for m in models if m not in ALL_MODELS]
    if invalid_models:
        print(f"âš ï¸ æœªçŸ¥æ¨¡å‹: {invalid_models}")
        print(f"å¯ç”¨æ¨¡å‹: {ALL_MODELS}")
        models = [m for m in models if m in ALL_MODELS]
    
    print(f"\nğŸ“‹ å¾®è°ƒè®¡åˆ’:")
    print(f"  ä»»åŠ¡: {tasks}")
    print(f"  æ¨¡å‹: {models}")
    
    # å¾®è°ƒç»“æœæ”¶é›†
    all_results = {}
    
    for task_name in tasks:
        config = FINETUNE_CONFIG[task_name].copy()
        
        # åº”ç”¨å‘½ä»¤è¡Œè¦†ç›–
        if args.lr is not None:
            config['lr'] = args.lr
        if args.epochs is not None:
            config['epochs'] = args.epochs
        if args.patience is not None:
            config['patience'] = args.patience
        
        print(f"\n{'#'*70}")
        print(f"# ä»»åŠ¡: {config['description']}")
        print(f"# è¶…å‚: lr={config['lr']}, epochs={config['epochs']}, patience={config['patience']}")
        print(f"{'#'*70}")
        
        task_results = {}
        
        for model_name in models:
            try:
                metrics, history = finetune_model(
                    model_name, task_name, df, config,
                    batch_size=args.batch_size,
                    verbose=not args.quiet
                )
                task_results[model_name] = {
                    'metrics': metrics,
                    'history': history
                }
            except Exception as e:
                print(f"âŒ å¾®è°ƒ {model_name} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        all_results[task_name] = task_results
    
    # æ‰“å°æœ€ç»ˆç»“æœæ±‡æ€»
    print("\n" + "=" * 70)
    print("ğŸ“Š å¾®è°ƒç»“æœæ±‡æ€»")
    print("=" * 70)
    
    for task_name, task_results in all_results.items():
        print(f"\nã€{FINETUNE_CONFIG[task_name]['description']}ã€‘")
        print("-" * 50)
        print(f"{'æ¨¡å‹':<20} {'MSE':>10} {'RMSE':>10} {'MAE':>10} {'RÂ²':>10}")
        print("-" * 50)
        
        # æŒ‰RÂ²æ’åº
        sorted_results = sorted(
            task_results.items(),
            key=lambda x: x[1]['metrics']['R2'],
            reverse=True
        )
        
        for i, (model_name, result) in enumerate(sorted_results):
            m = result['metrics']
            medal = "ğŸ¥‡" if i == 0 else ("ğŸ¥ˆ" if i == 1 else ("ğŸ¥‰" if i == 2 else "  "))
            print(f"{medal}{model_name:<18} {m['MSE']:>10.4f} {m['RMSE']:>10.4f} {m['MAE']:>10.4f} {m['R2']:>10.4f}")
    
    print("\n" + "=" * 70)
    print("âœ… å¾®è°ƒå®Œæˆï¼")
    print(f"   æ¨¡å‹å·²ä¿å­˜è‡³: {MODELS_DIR}")
    print("=" * 70)


if __name__ == "__main__":
    main()
