"""
è®­ç»ƒä¸è¯„ä¼°æ¨¡å—
åŠŸèƒ½ï¼š
1. è®­ç»ƒå¾ªç¯
2. è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼ˆMSE, RMSE, MAE, RÂ²ï¼‰
3. æ—©åœæœºåˆ¶
4. æ¨¡å‹ä¿å­˜ä¸åŠ è½½
"""
import os
import torch
import torch.nn as nn
import numpy as np
from tqdm import tqdm
import time
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from config import (
    DEVICE, LEARNING_RATE, NUM_EPOCHS, EARLY_STOPPING_PATIENCE,
    WEIGHT_DECAY, MODELS_DIR, LOGS_DIR
)
from datetime import datetime
import json


class EarlyStopping:
    """
    æ—©åœæœºåˆ¶ - æ”¯æŒå¤šç§è¯„ä¼°æŒ‡æ ‡ç­–ç•¥
    
    è¯„ä¼°æŒ‡æ ‡é€‰æ‹©å»ºè®®ï¼š
    - RÂ²ï¼ˆmode='r2'ï¼‰: é€‚åˆé•¿æœŸé¢„æµ‹ï¼Œæ›´å¥½åœ°åæ˜ æ¨¡å‹å¯¹æ•°æ®çš„è§£é‡Šèƒ½åŠ›
    - MSEï¼ˆmode='mse'ï¼‰: é€‚åˆçŸ­æœŸé¢„æµ‹ï¼Œç›´æ¥æœ€å°åŒ–é¢„æµ‹è¯¯å·®
    - ç»¼åˆæŒ‡æ ‡ï¼ˆmode='combined'ï¼‰: åŒæ—¶è€ƒè™‘RÂ²å’ŒMSEï¼Œæ¨èç”¨äºæ¨¡å‹å¾®è°ƒ
    """

    def __init__(self, patience=EARLY_STOPPING_PATIENCE, min_delta=0.001, mode='r2'):
        """
        åˆå§‹åŒ–æ—©åœ

        Args:
            patience: å®¹å¿çš„epochæ•°
            min_delta: æœ€å°æ”¹è¿›é‡
            mode: è¯„ä¼°æ¨¡å¼
                  'r2': ä½¿ç”¨RÂ²ä½œä¸ºæŒ‡æ ‡ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
                  'mse': ä½¿ç”¨MSEä½œä¸ºæŒ‡æ ‡ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
                  'combined': ç»¼åˆè€ƒè™‘RÂ²å’ŒMSE
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_model_state = None
        self.best_metrics = None

    def _get_score(self, metrics):
        """æ ¹æ®æ¨¡å¼è·å–è¯„ä¼°åˆ†æ•°"""
        if self.mode == 'mse':
            # MSEè¶Šå°è¶Šå¥½ï¼Œå–è´Ÿå€¼ä½¿å¾—è¶Šå¤§è¶Šå¥½
            return -metrics['MSE']
        elif self.mode == 'combined':
            # ç»¼åˆæŒ‡æ ‡ï¼šRÂ² - 0.1 * normalized_MSE
            # è¿™æ ·æ—¢è€ƒè™‘RÂ²åˆæƒ©ç½šè¿‡å¤§çš„MSE
            return metrics['R2'] - 0.1 * min(metrics['MSE'], 1.0)
        else:  # é»˜è®¤ 'r2'
            return metrics['R2']

    def __call__(self, metrics, model):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ

        Args:
            metrics: åŒ…å«R2ã€MSEã€RMSEã€MAEçš„å­—å…¸
            model: å½“å‰æ¨¡å‹
        """
        current_score = self._get_score(metrics)

        if self.best_score is None:
            self.best_score = current_score
            self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            self.best_metrics = metrics.copy()
        elif self._is_improvement(current_score):
            self.best_score = current_score
            self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            self.best_metrics = metrics.copy()
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True

    def _is_improvement(self, score):
        """æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿæ”¹è¿›ï¼ˆåˆ†æ•°è¶Šå¤§è¶Šå¥½ï¼‰"""
        return score > self.best_score + self.min_delta

    def load_best_model(self, model):
        """åŠ è½½æœ€ä½³æ¨¡å‹çŠ¶æ€"""
        if self.best_model_state is not None:
            model.load_state_dict(self.best_model_state)

    def get_best_metrics(self):
        """è·å–æœ€ä½³æ¨¡å‹çš„æŒ‡æ ‡"""
        return self.best_metrics
    
    def get_best_r2(self):
        """è·å–æœ€ä½³RÂ²å€¼ï¼ˆç”¨äºæ¨¡å‹å¯¹æ¯”ï¼‰"""
        if self.best_metrics:
            return self.best_metrics['R2']
        return None


def calculate_metrics(y_true, y_pred):
    """
    è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    
    Args:
        y_true: çœŸå®å€¼ (numpy array)
        y_pred: é¢„æµ‹å€¼ (numpy array)
        
    Returns:
        åŒ…å«å„æŒ‡æ ‡çš„å­—å…¸
    """
    # ç¡®ä¿æ˜¯numpyæ•°ç»„
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()
    
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2
    }


def train_epoch(model, dataloader, criterion, optimizer, device=DEVICE):
    """
    è®­ç»ƒä¸€ä¸ªepoch
    
    Args:
        model: æ¨¡å‹
        dataloader: æ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        device: è®¾å¤‡
        
    Returns:
        å¹³å‡æŸå¤±
    """
    model.train()
    total_loss = 0
    num_batches = 0
    
    for x, y in dataloader:
        x = x.to(device)
        y = y.to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
    
    return total_loss / num_batches if num_batches > 0 else 0


def evaluate(model, dataloader, criterion, device=DEVICE):
    """
    è¯„ä¼°æ¨¡å‹
    
    Args:
        model: æ¨¡å‹
        dataloader: æ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        device: è®¾å¤‡
        
    Returns:
        å¹³å‡æŸå¤±, æ‰€æœ‰é¢„æµ‹å€¼, æ‰€æœ‰çœŸå®å€¼
    """
    model.eval()
    total_loss = 0
    num_batches = 0
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            y = y.to(device)
            
            output = model(x)
            loss = criterion(output, y)
            
            total_loss += loss.item()
            num_batches += 1
            
            all_predictions.append(output.cpu().numpy())
            all_targets.append(y.cpu().numpy())
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    
    all_predictions = np.concatenate(all_predictions, axis=0)
    all_targets = np.concatenate(all_targets, axis=0)
    
    return avg_loss, all_predictions, all_targets


def train_model(model, train_loader, val_loader, model_name, task_name,
                num_epochs=NUM_EPOCHS, learning_rate=None, patience=None,
                lr=None, device=DEVICE, save_best=True, verbose=True,
                resume=False, metric_mode=None):
    """
    å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
    
    Args:
        model: æ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        model_name: æ¨¡å‹åç§°
        task_name: ä»»åŠ¡åç§° ('singlestep', 'multistep_16h')
        num_epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ ç‡ï¼ˆæ–°å‚æ•°åï¼‰
        patience: æ—©åœè€å¿ƒå€¼
        lr: å­¦ä¹ ç‡ï¼ˆå‘åå…¼å®¹ï¼‰
        device: è®¾å¤‡
        save_best: æ˜¯å¦ä¿å­˜æœ€ä½³æ¨¡å‹
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        resume: æ˜¯å¦ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ
        metric_mode: è¯„ä¼°æŒ‡æ ‡æ¨¡å¼ ('r2', 'mse', 'combined')
                    å¦‚æœä¸ºNoneï¼Œæ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©ï¼š
                    - multistep_16h: 'r2' (é•¿æœŸé¢„æµ‹ç”¨RÂ²)
                    - å…¶ä»–: 'mse' (çŸ­æœŸé¢„æµ‹ç”¨MSE)
        
    Returns:
        è®­ç»ƒå†å²å­—å…¸
    """
    # å¤„ç†å­¦ä¹ ç‡å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨learning_rateï¼Œç„¶åæ˜¯lrï¼Œæœ€åæ˜¯é»˜è®¤å€¼ï¼‰
    actual_lr = learning_rate if learning_rate is not None else (lr if lr is not None else LEARNING_RATE)
    # å¤„ç†æ—©åœè€å¿ƒå€¼
    actual_patience = patience if patience is not None else EARLY_STOPPING_PATIENCE
    
    # æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©è¯„ä¼°æŒ‡æ ‡æ¨¡å¼
    if metric_mode is None:
        if task_name == 'multistep_16h':
            metric_mode = 'r2'  # é•¿æœŸé¢„æµ‹ï¼šä½¿ç”¨RÂ²
        else:
            metric_mode = 'mse'  # çŸ­æœŸé¢„æµ‹ï¼šä½¿ç”¨MSE
    
    # å°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤
    start_epoch = 0
    previous_history = None
    model_path = os.path.join(MODELS_DIR, f"{model_name}_{task_name}.pth")
    
    if resume and os.path.exists(model_path):
        try:
            # PyTorch 2.6+ éœ€è¦è®¾ç½® weights_only=False æ¥åŠ è½½åŒ…å« numpy æ•°ç»„çš„æ£€æŸ¥ç‚¹
            checkpoint = torch.load(model_path, map_location=device, weights_only=False)
            
            # æ£€æŸ¥æ¨¡å‹ç»“æ„æ˜¯å¦å…¼å®¹
            checkpoint_state = checkpoint['model_state_dict']
            current_state = model.state_dict()
            
            # æ¯”è¾ƒå‚æ•°å½¢çŠ¶æ˜¯å¦åŒ¹é…
            compatible = True
            for key in current_state.keys():
                if key in checkpoint_state:
                    if current_state[key].shape != checkpoint_state[key].shape:
                        compatible = False
                        if verbose:
                            print(f"âš ï¸ æ¨¡å‹ç»“æ„å·²æ›´æ”¹ï¼Œå‚æ•° '{key}' å½¢çŠ¶ä¸åŒ¹é…:")
                            print(f"   æ£€æŸ¥ç‚¹: {checkpoint_state[key].shape} â†’ å½“å‰æ¨¡å‹: {current_state[key].shape}")
                        break
                else:
                    compatible = False
                    if verbose:
                        print(f"âš ï¸ æ¨¡å‹ç»“æ„å·²æ›´æ”¹ï¼Œç¼ºå°‘å‚æ•°: '{key}'")
                    break
            
            if compatible:
                model.load_state_dict(checkpoint_state)
                if 'history' in checkpoint:
                    previous_history = checkpoint['history']
                    # ä»ä¸Šæ¬¡è®­ç»ƒç»“æŸçš„epochç»§ç»­
                    start_epoch = len(previous_history.get('train_loss', []))
                if verbose:
                    prev_best_loss = previous_history.get('best_val_loss', 'N/A') if previous_history else 'N/A'
                    prev_best_epoch = previous_history.get('best_epoch', 'N/A') if previous_history else 'N/A'
                    # æ ¼å¼åŒ–æœ€ä½³æŸå¤±å€¼
                    loss_str = f"{prev_best_loss:.4f}" if isinstance(prev_best_loss, (int, float)) else str(prev_best_loss)
                    print(f"âœ… ä»æ£€æŸ¥ç‚¹æ¢å¤: {model_path}")
                    print(f"   å·²å®Œæˆ {start_epoch} ä¸ªepoch")
                    print(f"   ä¹‹å‰æœ€ä½³éªŒè¯æŸå¤±: {loss_str} (epoch {prev_best_epoch})")
            else:
                if verbose:
                    print(f"âš ï¸ é…ç½®å·²æ›´æ”¹ï¼Œæ£€æŸ¥ç‚¹ä¸å…¼å®¹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹")
                start_epoch = 0
                previous_history = None
                
        except Exception as e:
            if verbose:
                print(f"âš ï¸ æ— æ³•åŠ è½½æ£€æŸ¥ç‚¹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ: {e}")
            start_epoch = 0
            previous_history = None
    
    model = model.to(device)
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=actual_lr, weight_decay=WEIGHT_DECAY)
    
    # ä½¿ç”¨ CosineAnnealingWarmRestarts å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆæ›´é€‚åˆé•¿æœŸè®­ç»ƒï¼‰
    # ç»“åˆ ReduceLROnPlateau ä½œä¸ºåå¤‡
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=actual_lr * 0.01
    )
    plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=8
    )
    
    early_stopping = EarlyStopping(patience=actual_patience, mode=metric_mode)
    
    # åˆå§‹åŒ–å†å²è®°å½•ï¼ˆå¦‚æœæ˜¯ç»§ç»­è®­ç»ƒï¼Œåˆå¹¶ä¹‹å‰çš„å†å²ï¼‰
    history = {
        'train_loss': [],
        'val_loss': [],
        'val_metrics': [],
        'best_epoch': 0,
        'best_val_loss': float('inf'),
        'training_time': 0
    }
    
    if previous_history is not None:
        history['train_loss'] = previous_history.get('train_loss', [])
        history['val_loss'] = previous_history.get('val_loss', [])
        history['val_metrics'] = previous_history.get('val_metrics', [])
        history['best_epoch'] = previous_history.get('best_epoch', 0)
        history['best_val_loss'] = previous_history.get('best_val_loss', float('inf'))  # å…³é”®ï¼šä¿ç•™å†å²æœ€ä½³
        history['training_time'] = previous_history.get('training_time', 0)
        
        # é‡è¦ï¼šè®°å½•å†å²æœ€ä½³æŸå¤±ï¼Œç”¨äºåç»­å¯¹æ¯”
        history['_historical_best_val_loss'] = history['best_val_loss']
    
    start_time = time.time()
    
    # è®¡ç®—å‰©ä½™éœ€è¦è®­ç»ƒçš„è½®æ•°
    remaining_epochs = max(0, num_epochs - start_epoch)
    
    if verbose:
        mode_desc = {'r2': 'RÂ²(è¶Šå¤§è¶Šå¥½)', 'mse': 'MSE(è¶Šå°è¶Šå¥½)', 'combined': 'ç»¼åˆæŒ‡æ ‡'}
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒ {model_name} - {task_name}")
        print(f"{'='*60}")
        print(f"è®¾å¤‡: {device}")
        print(f"å­¦ä¹ ç‡: {actual_lr}")
        print(f"è¯„ä¼°æ¨¡å¼: {mode_desc.get(metric_mode, metric_mode)}")
        if start_epoch > 0:
            print(f"ç»§ç»­è®­ç»ƒ: ä» epoch {start_epoch + 1} åˆ° {num_epochs}")
        else:
            print(f"è®­ç»ƒè½®æ•°: {num_epochs}")
        print(f"æ—©åœè€å¿ƒå€¼: {actual_patience}")
    
    if remaining_epochs == 0:
        if verbose:
            print("âœ… æ¨¡å‹å·²å®ŒæˆæŒ‡å®šè½®æ•°çš„è®­ç»ƒï¼Œæ— éœ€ç»§ç»­")
        return history
    
    progress_bar = tqdm(range(remaining_epochs), desc=f"Training {model_name}")
    
    for epoch_idx in progress_bar:
        actual_epoch = start_epoch + epoch_idx
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
        
        # éªŒè¯
        val_loss, val_preds, val_targets = evaluate(model, val_loader, criterion, device)
        
        # è®¡ç®—æŒ‡æ ‡
        val_metrics = calculate_metrics(val_targets, val_preds)
        
        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_metrics'].append(val_metrics)
        
        # æ›´æ–°å­¦ä¹ ç‡ï¼ˆä½¿ç”¨ä½™å¼¦é€€ç« + å¹³å°æ£€æµ‹åŒè°ƒåº¦å™¨ï¼‰
        scheduler.step(actual_epoch)
        plateau_scheduler.step(val_loss)
        
        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']
        
        # è­¦å‘Šï¼šå­¦ä¹ ç‡è¿‡ä½å¯¼è‡´è®­ç»ƒåœæ»
        if current_lr < 1e-6 and actual_epoch > 20:
            if verbose and actual_epoch % 20 == 0:
                print(f"âš ï¸  è­¦å‘Šï¼šå­¦ä¹ ç‡è¿‡ä½ ({current_lr:.2e})ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒåœæ»ï¼Œå»ºè®®å¢åŠ å­¦ä¹ ç‡")
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.set_postfix({
            'train_loss': f'{train_loss:.4f}',
            'val_loss': f'{val_loss:.4f}',
            'val_rmse': f'{val_metrics["RMSE"]:.4f}',
            'lr': f'{current_lr:.6f}'
        })
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹ï¼ˆç”±EarlyStoppingç±»å†…éƒ¨å¤„ç†ï¼‰
        early_stopping(val_metrics, model)

        # æ›´æ–°å†å²è®°å½•ä¸­çš„æœ€ä½³ä¿¡æ¯
        if early_stopping.best_metrics is not None:
            history['best_val_loss'] = early_stopping.best_metrics['MSE']
            history['best_epoch'] = actual_epoch + 1
            history['best_r2'] = early_stopping.best_metrics['R2']
            history['best_score'] = early_stopping.best_score  # ä¿å­˜ç”¨äºå¯¹æ¯”çš„åˆ†æ•°
            history['metric_mode'] = metric_mode  # ä¿å­˜ä½¿ç”¨çš„è¯„ä¼°æ¨¡å¼
        if early_stopping.early_stop:
            if verbose:
                print(f"\næ—©åœè§¦å‘äº epoch {actual_epoch + 1}")
            break
    
    # åŠ è½½æœ¬æ¬¡è®­ç»ƒçš„æœ€ä½³æ¨¡å‹ï¼ˆç”¨äºåç»­å¯¹æ¯”ï¼‰
    early_stopping.load_best_model(model)
    current_best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
    
    history['training_time'] = time.time() - start_time
    
    # ==================== å…³é”®ä¿®å¤ï¼šå¯¹æ¯”æ–°æ—§æœ€ä½³æ¨¡å‹ï¼Œä¿ç•™å†å²æœ€ä½³ ====================
    model_filename = f"{model_name}_{task_name}.pth"
    model_path = os.path.join(MODELS_DIR, model_filename)
    
    # åˆå¹¶å®Œæ•´è®­ç»ƒå†å²ï¼ˆæ— è®ºæ˜¯å¦æ”¹è¿›éƒ½è¦åˆå¹¶ï¼‰
    merged_history = history.copy()
    if previous_history is not None:
        # åˆå¹¶å†å²è®°å½•
        merged_history['train_loss'] = previous_history.get('train_loss', []) + history['train_loss']
        merged_history['val_loss'] = previous_history.get('val_loss', []) + history['val_loss']
        merged_history['val_metrics'] = previous_history.get('val_metrics', []) + history['val_metrics']
        merged_history['training_time'] = previous_history.get('training_time', 0) + history['training_time']
        
        # å¯¹æ¯”å†å²æœ€ä½³å’Œæœ¬æ¬¡æœ€ä½³ï¼Œæ ¹æ®metric_modeé€‰æ‹©å¯¹æ¯”æ–¹å¼
        prev_best_score = previous_history.get('best_score', None)
        current_best_score = history.get('best_score', early_stopping.best_score)
        
        # å¦‚æœå†å²æ²¡æœ‰best_scoreï¼ˆæ—§ç‰ˆæœ¬æ¨¡å‹ï¼‰ï¼Œä½¿ç”¨RÂ²ä½œä¸ºå›é€€
        if prev_best_score is None:
            prev_best_score = previous_history.get('best_r2', float('-inf'))
            # å¦‚æœmetric_modeæ˜¯mseï¼Œéœ€è¦å–è´Ÿå€¼
            if metric_mode == 'mse':
                prev_best_mse = previous_history.get('best_val_loss', float('inf'))
                prev_best_score = -prev_best_mse

        if current_best_score > prev_best_score:
            # æœ¬æ¬¡è®­ç»ƒäº§ç”Ÿäº†æ›´å¥½çš„æ¨¡å‹
            best_val_loss = history['best_val_loss']
            best_epoch = start_epoch + history['best_epoch']  # è°ƒæ•´epochç¼–å·
            best_model_state = current_best_model_state
            best_r2 = history.get('best_r2', early_stopping.get_best_r2())
            history_improved = True
        else:
            # å†å²æ¨¡å‹æ›´å¥½ï¼Œä¿ç•™å†å²æœ€ä½³
            best_val_loss = previous_history.get('best_val_loss', history['best_val_loss'])
            best_epoch = previous_history.get('best_epoch', 0)
            best_r2 = previous_history.get('best_r2', 0)
            # éœ€è¦ä»æ—§æ£€æŸ¥ç‚¹åŠ è½½å†å²æœ€ä½³æ¨¡å‹æƒé‡
            if os.path.exists(model_path):
                old_checkpoint = torch.load(model_path, map_location=device, weights_only=False)
                best_model_state = old_checkpoint['model_state_dict']
                # ==================== å…³é”®ä¿®å¤ï¼šæŠŠmodelå¯¹è±¡ä¹ŸåŠ è½½ä¸ºå†å²æœ€ä½³ ====================
                # è¿™æ ·è¿”å›ç»™main.pyçš„modelæ‰æ˜¯å†å²æœ€ä½³ï¼Œtest_modelæµ‹è¯•çš„æ‰æ˜¯çœŸæ­£çš„æœ€ä½³æ¨¡å‹
                model.load_state_dict(best_model_state)
                if verbose:
                    print(f"ğŸ”„ å·²å°†æ¨¡å‹å¯¹è±¡æ¢å¤ä¸ºå†å²æœ€ä½³çŠ¶æ€ï¼ˆç”¨äºåç»­æµ‹è¯•ï¼‰")
            else:
                best_model_state = current_best_model_state
            history_improved = False
    else:
        # é¦–æ¬¡è®­ç»ƒ
        best_val_loss = history['best_val_loss']
        best_epoch = history['best_epoch']
        best_model_state = current_best_model_state
        best_r2 = history.get('best_r2', early_stopping.get_best_r2())
        history_improved = True
        current_best_score = history.get('best_score', early_stopping.best_score)
    
    # æ›´æ–°åˆå¹¶åçš„å†å²è®°å½•ä¸­çš„æœ€ä½³ä¿¡æ¯
    merged_history['best_val_loss'] = best_val_loss
    merged_history['best_epoch'] = best_epoch
    merged_history['best_r2'] = best_r2
    merged_history['best_score'] = current_best_score if history_improved else prev_best_score
    merged_history['metric_mode'] = metric_mode
    
    # æ‰“å°å¯¹æ¯”ä¿¡æ¯
    if verbose:
        mode_desc = {'r2': 'RÂ²(è¶Šå¤§è¶Šå¥½)', 'mse': 'MSE(è¶Šå°è¶Šå¥½)', 'combined': 'ç»¼åˆæŒ‡æ ‡'}
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒå†å²åˆå¹¶åˆ†æï¼ˆè¯„ä¼°æ¨¡å¼: {mode_desc.get(metric_mode, metric_mode)}ï¼‰ï¼š")
        if previous_history is not None:
            prev_best_r2 = previous_history.get('best_r2', float('-inf'))
            current_best_r2 = history.get('best_r2', early_stopping.get_best_r2())
            prev_best_loss = previous_history.get('best_val_loss', float('inf'))
            current_best_loss = history['best_val_loss']

            print(f"  å†å²æœ€ä½³: RÂ²={prev_best_r2:.4f}, MSE={prev_best_loss:.4f} (epoch {previous_history.get('best_epoch', '?')})")
            print(f"  æœ¬æ¬¡æœ€ä½³: RÂ²={current_best_r2:.4f}, MSE={current_best_loss:.4f} (epoch {start_epoch + history['best_epoch']})")

            if history_improved:
                if metric_mode == 'mse':
                    improvement = prev_best_loss - current_best_loss
                    print(f"  âœ… æœ¬æ¬¡è®­ç»ƒæ”¹è¿›: MSEå‡å°‘ {improvement:.4f}")
                else:
                    improvement = current_best_r2 - prev_best_r2
                    print(f"  âœ… æœ¬æ¬¡è®­ç»ƒæ”¹è¿›: RÂ²æå‡ {improvement:.4f}")
            else:
                print(f"  âš ï¸  æœ¬æ¬¡è®­ç»ƒæœªæ”¹è¿›ï¼Œä¿ç•™å†å²æœ€ä½³æ¨¡å‹")
        
        final_r2 = best_r2 if best_r2 else early_stopping.get_best_r2()
        print(f"  æœ€ç»ˆä¿ç•™: RÂ²={final_r2:.4f}, MSE={best_val_loss:.4f} (epoch {best_epoch})")
        print(f"  ç´¯è®¡è®­ç»ƒè½®æ•°: {len(merged_history['train_loss'])}")
        print(f"{'='*60}\n")
    
    # ä¿å­˜æ¨¡å‹ï¼ˆå§‹ç»ˆä¿å­˜å†å²æœ€ä½³æƒé‡ + å®Œæ•´è®­ç»ƒå†å²ï¼‰
    if save_best:
        torch.save({
            'model_state_dict': best_model_state,  # å†å²æœ€ä½³æƒé‡
            'model_name': model_name,
            'task_name': task_name,
            'history': merged_history,  # å®Œæ•´è®­ç»ƒå†å²ï¼ˆåŒ…å«æ‰€æœ‰å¾®è°ƒè¿‡ç¨‹ï¼‰
            'total_epochs': len(merged_history['train_loss']),
        }, model_path)
        if verbose:
            if history_improved:
                print(f"âœ… å·²ä¿å­˜æ”¹è¿›åçš„æ¨¡å‹è‡³: {model_path}")
            else:
                print(f"âœ… å·²æ›´æ–°è®­ç»ƒå†å²ï¼Œä¿ç•™å†å²æœ€ä½³æ¨¡å‹: {model_path}")
        
        # ä¿å­˜è®­ç»ƒæ—¥å¿—ï¼ˆè¿½åŠ æ¨¡å¼ï¼Œä¿ç•™æ‰€æœ‰å¾®è°ƒå†å²ï¼‰
        _save_training_log(model_name, task_name, merged_history, metric_mode, 
                          actual_lr, actual_patience, history_improved, start_epoch)
    
    # è¿”å›åˆå¹¶åçš„å®Œæ•´å†å²
    return merged_history


def _save_training_log(model_name, task_name, history, metric_mode, lr, patience, improved, start_epoch):
    """
    ä¿å­˜è®­ç»ƒæ—¥å¿—åˆ°logsç›®å½•ï¼ˆè¿½åŠ æ¨¡å¼ï¼Œä¿ç•™æ‰€æœ‰è®­ç»ƒ/å¾®è°ƒè®°å½•ï¼‰
    
    Args:
        model_name: æ¨¡å‹åç§°
        task_name: ä»»åŠ¡åç§°
        history: è®­ç»ƒå†å²
        metric_mode: è¯„ä¼°æ¨¡å¼
        lr: å­¦ä¹ ç‡
        patience: æ—©åœè€å¿ƒå€¼
        improved: æ˜¯å¦æœ‰æ”¹è¿›
        start_epoch: å¼€å§‹è®­ç»ƒçš„epoch
    """
    log_file = os.path.join(LOGS_DIR, f'{model_name}_{task_name}_training_log.jsonl')
    
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'model_name': model_name,
        'task_name': task_name,
        'metric_mode': metric_mode,
        'learning_rate': lr,
        'patience': patience,
        'start_epoch': start_epoch,
        'end_epoch': len(history.get('train_loss', [])),
        'best_epoch': history.get('best_epoch', 0),
        'best_r2': history.get('best_r2', None),
        'best_mse': history.get('best_val_loss', None),
        'total_training_time': history.get('training_time', 0),
        'improved': improved,
    }
    
    # è¿½åŠ åˆ°æ—¥å¿—æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    print(f"ğŸ“ è®­ç»ƒæ—¥å¿—å·²è¿½åŠ è‡³: {log_file}")


def test_model(model, test_loader, scaler_targets, device=DEVICE):
    """
    æµ‹è¯•æ¨¡å‹å¹¶è¿”å›è¯¦ç»†ç»“æœ
    
    Args:
        model: æ¨¡å‹
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        scaler_targets: ç›®æ ‡æ ‡å‡†åŒ–å™¨ï¼ˆç”¨äºåæ ‡å‡†åŒ–ï¼‰
        device: è®¾å¤‡
        
    Returns:
        æµ‹è¯•æŒ‡æ ‡å­—å…¸, é¢„æµ‹å€¼, çœŸå®å€¼
    """
    model = model.to(device)
    model.eval()
    
    criterion = nn.MSELoss()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for x, y in test_loader:
            x = x.to(device)
            y = y.to(device)
            
            output = model(x)
            
            all_predictions.append(output.cpu().numpy())
            all_targets.append(y.cpu().numpy())
    
    all_predictions = np.concatenate(all_predictions, axis=0)
    all_targets = np.concatenate(all_targets, axis=0)
    
    # åæ ‡å‡†åŒ–
    original_shape = all_predictions.shape
    all_predictions_flat = all_predictions.reshape(-1, original_shape[-1])
    all_targets_flat = all_targets.reshape(-1, original_shape[-1])
    
    all_predictions_inv = scaler_targets.inverse_transform(all_predictions_flat)
    all_targets_inv = scaler_targets.inverse_transform(all_targets_flat)
    
    all_predictions_inv = all_predictions_inv.reshape(original_shape)
    all_targets_inv = all_targets_inv.reshape(original_shape)
    
    # è®¡ç®—æŒ‡æ ‡ï¼ˆä½¿ç”¨åŸå§‹å°ºåº¦ï¼‰
    metrics = calculate_metrics(all_targets_inv, all_predictions_inv)
    
    # è®¡ç®—æ¯ä¸ªç›®æ ‡çš„æŒ‡æ ‡
    metrics_per_target = []
    for i in range(original_shape[-1]):
        target_metrics = calculate_metrics(
            all_targets_inv[:, :, i],
            all_predictions_inv[:, :, i]
        )
        metrics_per_target.append(target_metrics)
    
    return metrics, metrics_per_target, all_predictions_inv, all_targets_inv


def load_model(model, model_path):
    """
    åŠ è½½ä¿å­˜çš„æ¨¡å‹
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŠ è½½äº†æƒé‡çš„æ¨¡å‹, è®­ç»ƒå†å²
    """
    # PyTorch 2.6+ éœ€è¦è®¾ç½® weights_only=False
    checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    history = checkpoint.get('history', {})
    return model, history


def print_test_results(model_name, task_name, metrics, metrics_per_target, target_names):
    """
    æ‰“å°æµ‹è¯•ç»“æœ
    
    Args:
        model_name: æ¨¡å‹åç§°
        task_name: ä»»åŠ¡åç§°
        metrics: æ€»ä½“æŒ‡æ ‡
        metrics_per_target: æ¯ä¸ªç›®æ ‡çš„æŒ‡æ ‡
        target_names: ç›®æ ‡åç§°åˆ—è¡¨
    """
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœ: {model_name} - {task_name}")
    print(f"{'='*60}")
    
    print(f"\næ€»ä½“æŒ‡æ ‡:")
    print(f"  MSE:  {metrics['MSE']:.4f}")
    print(f"  RMSE: {metrics['RMSE']:.4f}")
    print(f"  MAE:  {metrics['MAE']:.4f}")
    print(f"  RÂ²:   {metrics['R2']:.4f}")
    
    print(f"\nå„ç›®æ ‡æŒ‡æ ‡:")
    for i, (name, m) in enumerate(zip(target_names, metrics_per_target)):
        print(f"\n  {name}:")
        print(f"    MSE:  {m['MSE']:.4f}")
        print(f"    RMSE: {m['RMSE']:.4f}")
        print(f"    MAE:  {m['MAE']:.4f}")
        print(f"    RÂ²:   {m['R2']:.4f}")


def compare_models(results_dict):
    """
    å¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„ç»“æœ
    
    Args:
        results_dict: {model_name: {task_name: metrics}}
        
    Returns:
        å¯¹æ¯”ç»“æœDataFrame
    """
    import pandas as pd
    
    rows = []
    for model_name, tasks in results_dict.items():
        for task_name, metrics in tasks.items():
            row = {
                'Model': model_name,
                'Task': task_name,
                'MSE': metrics['MSE'],
                'RMSE': metrics['RMSE'],
                'MAE': metrics['MAE'],
                'R2': metrics['R2']
            }
            rows.append(row)
    
    df = pd.DataFrame(rows)
    return df


if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒæ¨¡å—
    print("æµ‹è¯•è®­ç»ƒæ¨¡å—...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    from torch.utils.data import TensorDataset, DataLoader
    
    batch_size = 32
    input_len = 8
    output_len = 1
    num_features = 20
    num_targets = 3
    num_samples = 1000
    
    # æ¨¡æ‹Ÿæ•°æ®
    X = torch.randn(num_samples, input_len, num_features)
    Y = torch.randn(num_samples, output_len, num_targets)
    
    dataset = TensorDataset(X, Y)
    train_size = int(0.7 * len(dataset))
    val_size = int(0.2 * len(dataset))
    test_size = len(dataset) - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)
    
    # æµ‹è¯•è®­ç»ƒ
    from models import LinearModel
    model = LinearModel(input_len, output_len, num_features, num_targets)
    
    history = train_model(
        model, train_loader, val_loader,
        model_name='Linear_test',
        task_name='test',
        num_epochs=5,
        save_best=False,
        verbose=True
    )
    
    print(f"\nè®­ç»ƒå†å²:")
    print(f"  æœ€ä½³epoch: {history['best_epoch']}")
    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {history['best_val_loss']:.4f}")
    
    print("\nè®­ç»ƒæ¨¡å—æµ‹è¯•å®Œæˆï¼")
