"""
é…ç½®æ–‡ä»¶ï¼šå®šä¹‰æ‰€æœ‰è¶…å‚æ•°å’Œè·¯å¾„é…ç½®
æ”¯æŒè‡ªåŠ¨æ£€æµ‹GPUï¼Œé€‚é…æœ¬åœ°Windowså’Œè¿œç¨‹LinuxæœåŠ¡å™¨è®­ç»ƒ
"""
import os
import sys
# ==================== è§£å†³æœåŠ¡å™¨æ— å›¾å½¢ç•Œé¢é—®é¢˜ï¼ˆå¿…é¡»æœ€å…ˆæ‰§è¡Œï¼‰====================
# åœ¨æ— å¤´LinuxæœåŠ¡å™¨ä¸Šè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…Qtæ’ä»¶é”™è¯¯
if sys.platform.startswith('linux'):
    if not os.environ.get('DISPLAY'):
        os.environ['QT_QPA_PLATFORM'] = 'offscreen'
        # è®¾ç½®matplotlibåç«¯ä¸ºAggï¼ˆå¦‚æœè¿˜æ²¡è®¾ç½®ï¼‰
        import matplotlib
        matplotlib.use('Agg')
import torch

# ==================== è®¾å¤‡è‡ªåŠ¨æ£€æµ‹ ====================
def get_device():
    """è‡ªåŠ¨æ£€æµ‹å¹¶è¿”å›æœ€ä½³å¯ç”¨è®¾å¤‡"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸš€ æ£€æµ‹åˆ°GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        return device
    else:
        print("ğŸ’» ä½¿ç”¨CPUè®­ç»ƒï¼ˆå»ºè®®åœ¨GPUæœåŠ¡å™¨ä¸Šè¿è¡Œä»¥åŠ é€Ÿï¼‰")
        return torch.device('cpu')

# ==================== å¹³å°æ£€æµ‹ ====================
IS_WINDOWS = sys.platform == 'win32'
IS_LINUX = sys.platform.startswith('linux')
print(f"ğŸ“ è¿è¡Œå¹³å°: {'Windows' if IS_WINDOWS else 'Linux' if IS_LINUX else sys.platform}")

# ==================== è·¯å¾„é…ç½® ====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_DIR = os.path.join(BASE_DIR, 'dataset')
MODELS_DIR = os.path.join(BASE_DIR, 'models')
RESULTS_DIR = os.path.join(BASE_DIR, 'results')
LOGS_DIR = os.path.join(BASE_DIR, 'logs')

# åˆ›å»ºå¿…è¦çš„ç›®å½•
for dir_path in [MODELS_DIR, RESULTS_DIR, LOGS_DIR]:
    os.makedirs(dir_path, exist_ok=True)

# ==================== æ•°æ®é…ç½® ====================
# æ•°æ®é›†è·¯å¾„
DATA_PATHS = {
    '10m': os.path.join(DATASET_DIR, 'WindSpeed_10m', 'data'),
    '50m': os.path.join(DATASET_DIR, 'WindSpeed_50m', 'data'),
    '100m': os.path.join(DATASET_DIR, 'WindSpeed_100m', 'data'),
}

# ç‰¹å¾åˆ—åï¼ˆåŸå§‹æ•°æ®é›†ä¸­çš„åˆ—åï¼‰
FEATURE_COLS = [
    'DirectionAvg',      # é£å‘
    'TemperatureAvg',    # æ¸©åº¦
    'PressureAvg',       # æ°”å‹
    'HumidtyAvg',        # æ¹¿åº¦
]

# ç›®æ ‡åˆ—ï¼ˆæˆ‘ä»¬è¦é¢„æµ‹çš„ï¼‰
TARGET_COL = 'SpeedAvg'  # é£é€Ÿ

# æ—¶é—´æˆ³åˆ—
TIMESTAMP_COL = 'Date & Time Stamp'

# é«˜åº¦åˆ—
HEIGHT_COL = 'height'

# ==================== åºåˆ—é…ç½® ====================
# å•æ­¥é¢„æµ‹é…ç½®
SINGLE_STEP_INPUT_LEN = 8   # è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆ8å°æ—¶ï¼‰
SINGLE_STEP_OUTPUT_LEN = 1  # è¾“å‡ºåºåˆ—é•¿åº¦ï¼ˆ1å°æ—¶ï¼‰

# å¤šæ­¥é¢„æµ‹é…ç½® - ä»»åŠ¡1ï¼š8å°æ—¶é¢„æµ‹1å°æ—¶
MULTI_STEP_1_INPUT_LEN = 8
MULTI_STEP_1_OUTPUT_LEN = 1

# å¤šæ­¥é¢„æµ‹é…ç½® - ä»»åŠ¡2ï¼š8å°æ—¶é¢„æµ‹16å°æ—¶
MULTI_STEP_2_INPUT_LEN = 8
MULTI_STEP_2_OUTPUT_LEN = 16

# ==================== æ•°æ®é›†åˆ’åˆ†é…ç½® ====================
TRAIN_RATIO = 0.7
VAL_RATIO = 0.2
TEST_RATIO = 0.1

# ==================== è®­ç»ƒé…ç½® ====================
DEVICE = get_device()

# æ ¹æ®è®¾å¤‡è‡ªåŠ¨è°ƒæ•´batch_size
# GPUå¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch_sizeåŠ é€Ÿè®­ç»ƒ
if torch.cuda.is_available():
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory >= 10:  # RTX 3060 æœ‰12GBæ˜¾å­˜
        BATCH_SIZE = 128
    elif gpu_memory >= 6:
        BATCH_SIZE = 64
    else:
        BATCH_SIZE = 32
else:
    BATCH_SIZE = 64  # CPUé»˜è®¤

LEARNING_RATE = 0.001
NUM_EPOCHS = 100
EARLY_STOPPING_PATIENCE = 15
WEIGHT_DECAY = 1e-5

print(f"âš™ï¸  Batch Size: {BATCH_SIZE}")

# ==================== æ¨¡å‹é…ç½® ====================
# Linearæ¨¡å‹é…ç½®
LINEAR_CONFIG = {
    'hidden_sizes': [128, 64, 32],
    'dropout': 0.2,
}

# LSTMæ¨¡å‹é…ç½®
LSTM_CONFIG = {
    'hidden_size': 128,
    'num_layers': 2,
    'dropout': 0.2,
    'bidirectional': True,
}

# Transformeræ¨¡å‹é…ç½®
TRANSFORMER_CONFIG = {
    'd_model': 64,
    'nhead': 4,
    'num_encoder_layers': 3,
    'num_decoder_layers': 3,
    'dim_feedforward': 256,
    'dropout': 0.1,
}

# ==================== åˆ›æ–°æ¨¡å‹é…ç½® ====================
# CNN-LSTMæ··åˆæ¨¡å‹é…ç½®
CNN_LSTM_CONFIG = {
    'cnn_channels': [32, 64],
    'kernel_size': 3,
    'lstm_hidden_size': 64,
    'lstm_num_layers': 2,
    'dropout': 0.2,
}

# Attention-LSTMæ¨¡å‹é…ç½®
ATTENTION_LSTM_CONFIG = {
    'hidden_size': 128,
    'num_layers': 2,
    'attention_heads': 4,
    'dropout': 0.2,
}

# TCN (Temporal Convolutional Network) é…ç½®
# ä¼˜åŒ–ç‰ˆæœ¬ï¼šå‡å°‘é€šé“æ•°ä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦
TCN_CONFIG = {
    'num_channels': [32, 64, 64],  # å‡å°‘é€šé“æ•°
    'kernel_size': 3,
    'dropout': 0.2,
}

# é›†æˆæ¨¡å‹é…ç½®
ENSEMBLE_CONFIG = {
    'models': ['Linear', 'LSTM', 'Transformer'],
    'weights': 'learned',  # 'equal', 'learned', 'stacking'
}

# ==================== éšæœºç§å­ ====================
RANDOM_SEED = 42

def set_seed(seed=RANDOM_SEED):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯å¤ç°æ€§"""
    import random
    import numpy as np
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
