"""
ç”Ÿæˆå„æ¨¡å‹çš„é¢„æµ‹ç»“æœå¯è§†åŒ–å›¾
åŠŸèƒ½ï¼š
1. å¯¹æ¯”çœŸå®å€¼ä¸é¢„æµ‹å€¼çš„æ—¶åºå›¾
2. æ•£ç‚¹å›¾ï¼ˆé¢„æµ‹å€¼ vs çœŸå®å€¼ï¼‰
3. å¤šæ­¥é¢„æµ‹æ›²çº¿å›¾
4. è¯¯å·®åˆ†å¸ƒå›¾
"""
import os
import sys
import torch
import numpy as np
import pandas as pd

# è®¾ç½®matplotlibåç«¯
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆWindowsï¼‰
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 150
plt.rcParams['savefig.dpi'] = 150

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from config import MODELS_DIR, RESULTS_DIR, DEVICE, SINGLE_STEP_INPUT_LEN, MULTI_STEP_INPUT_LEN
from data_loader import load_all_data, preprocess_data, create_dataloaders
from models import get_model
from models_innovative import get_innovative_model
from models_advanced import get_advanced_model
from models_simple import get_simple_model

# åˆ›å»ºé¢„æµ‹ç»“æœä¿å­˜ç›®å½•
PREDICTION_PLOTS_DIR = os.path.join(RESULTS_DIR, 'prediction_plots')
os.makedirs(PREDICTION_PLOTS_DIR, exist_ok=True)

# æ¨¡å‹åˆ—è¡¨åŠå…¶å¯¹åº”çš„è·å–å‡½æ•°
MODEL_GETTERS = {
    # åŸºç¡€æ¨¡å‹
    'Linear': ('basic', get_model),
    'LSTM': ('basic', get_model),
    'Transformer': ('basic', get_model),
    # åˆ›æ–°æ¨¡å‹
    'DLinear': ('advanced', get_advanced_model),
    'TCN': ('innovative', get_innovative_model),
    'WaveNet': ('innovative', get_innovative_model),
    'LSTNet': ('innovative', get_innovative_model),
    'CNN_LSTM': ('innovative', get_innovative_model),
    'HeightAttention': ('advanced', get_advanced_model),
    # ç®€å•æ¨¡å‹
    'TrendLinear': ('simple', get_simple_model),
    'WindShear': ('simple', get_simple_model),
    'Persistence': ('simple', get_simple_model),
}

MODELS = list(MODEL_GETTERS.keys())

TARGET_NAMES = ['10m Wind Speed', '50m Wind Speed', '100m Wind Speed']

# é…ç½®å‚æ•°
NUM_FEATURES = 21
NUM_TARGETS = 3


def load_model(model_name, task_type, input_len, output_len):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    if task_type == 'singlestep':
        model_path = os.path.join(MODELS_DIR, f'{model_name}_singlestep.pth')
        actual_output_len = 1
    else:
        model_path = os.path.join(MODELS_DIR, f'{model_name}_multistep_16h.pth')
        actual_output_len = 16
    
    if not os.path.exists(model_path):
        print(f"  âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None
    
    try:
        # è·å–æ¨¡å‹ç±»åˆ«å’Œè·å–å‡½æ•°
        model_type, model_getter = MODEL_GETTERS[model_name]
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = model_getter(model_name, input_len, actual_output_len, NUM_FEATURES, NUM_TARGETS)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(DEVICE)
        model.eval()
        return model
    except Exception as e:
        print(f"  âŒ åŠ è½½æ¨¡å‹å¤±è´¥ ({model_name}): {e}")
        return None


def get_predictions(model, test_loader):
    """è·å–æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹ç»“æœ"""
    y_true_list = []
    y_pred_list = []
    
    model.eval()
    with torch.no_grad():
        for X, y in test_loader:
            X = X.to(DEVICE)
            pred = model(X)
            y_true_list.append(y.cpu().numpy())
            y_pred_list.append(pred.cpu().numpy())
    
    y_true = np.concatenate(y_true_list, axis=0)
    y_pred = np.concatenate(y_pred_list, axis=0)
    
    return y_true, y_pred


def plot_predictions_comparison(y_true, y_pred, model_name, task_name, num_samples=200, save_path=None):
    """
    ç»˜åˆ¶é¢„æµ‹ç»“æœå¯¹æ¯”å›¾ï¼ˆçœŸå®å€¼ vs é¢„æµ‹å€¼ï¼‰
    """
    num_targets = y_true.shape[-1]
    fig, axes = plt.subplots(num_targets, 1, figsize=(14, 4*num_targets))
    
    if num_targets == 1:
        axes = [axes]
    
    for i, (ax, name) in enumerate(zip(axes, TARGET_NAMES)):
        # å–ç¬¬ä¸€ä¸ªè¾“å‡ºæ­¥é•¿çš„é¢„æµ‹
        true_vals = y_true[:num_samples, 0, i]
        pred_vals = y_pred[:num_samples, 0, i]
        
        x = range(len(true_vals))
        
        ax.plot(x, true_vals, 'b-', label='Actual', linewidth=1.5, alpha=0.8)
        ax.plot(x, pred_vals, 'r--', label='Predicted', linewidth=1.5, alpha=0.8)
        ax.fill_between(x, true_vals, pred_vals, alpha=0.2, color='gray')
        
        # è®¡ç®—è¯¥ç›®æ ‡çš„æŒ‡æ ‡
        r2 = r2_score(true_vals, pred_vals)
        rmse = np.sqrt(mean_squared_error(true_vals, pred_vals))
        
        ax.set_xlabel('Sample Index', fontsize=11)
        ax.set_ylabel('Wind Speed (m/s)', fontsize=11)
        ax.set_title(f'{name} (RÂ²={r2:.4f}, RMSE={rmse:.4f} m/s)', fontsize=12)
        ax.legend(loc='upper right', fontsize=10)
        ax.grid(True, alpha=0.3)
    
    plt.suptitle(f'{model_name} - {task_name} Prediction Results', fontsize=14, y=1.02)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"    âœ… ä¿å­˜: {os.path.basename(save_path)}")
    
    plt.close()


def plot_scatter(y_true, y_pred, model_name, task_name, save_path=None):
    """
    ç»˜åˆ¶æ•£ç‚¹å›¾ï¼ˆé¢„æµ‹å€¼ vs çœŸå®å€¼ï¼‰
    """
    num_targets = y_true.shape[-1]
    fig, axes = plt.subplots(1, num_targets, figsize=(5*num_targets, 5))
    
    if num_targets == 1:
        axes = [axes]
    
    for i, (ax, name) in enumerate(zip(axes, TARGET_NAMES)):
        true_vals = y_true[:, :, i].flatten()
        pred_vals = y_pred[:, :, i].flatten()
        
        # æ•£ç‚¹å›¾
        ax.scatter(true_vals, pred_vals, alpha=0.3, s=10, c='steelblue')
        
        # ç†æƒ³çº¿
        min_val = min(true_vals.min(), pred_vals.min())
        max_val = max(true_vals.max(), pred_vals.max())
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Ideal')
        
        # è®¡ç®—RÂ²
        r2 = r2_score(true_vals, pred_vals)
        
        ax.set_xlabel('Actual (m/s)', fontsize=11)
        ax.set_ylabel('Predicted (m/s)', fontsize=11)
        ax.set_title(f'{name}\nRÂ² = {r2:.4f}', fontsize=12)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.set_aspect('equal', adjustable='box')
    
    plt.suptitle(f'{model_name} - {task_name}', fontsize=14, y=1.02)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"    âœ… ä¿å­˜: {os.path.basename(save_path)}")
    
    plt.close()


def plot_multistep_curves(y_true, y_pred, model_name, target_idx=0, sample_indices=None, save_path=None):
    """
    ç»˜åˆ¶å¤šæ­¥é¢„æµ‹æ›²çº¿å›¾ï¼ˆå±•ç¤º16ä¸ªé¢„æµ‹æ­¥é•¿ï¼‰
    """
    if sample_indices is None:
        # é»˜è®¤é€‰æ‹©4ä¸ªä»£è¡¨æ€§æ ·æœ¬
        n = len(y_true)
        sample_indices = [0, n//4, n//2, 3*n//4]
    
    num_samples = len(sample_indices)
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()
    
    output_len = y_true.shape[1]
    x = range(1, output_len + 1)
    
    for ax, idx in zip(axes, sample_indices):
        true_vals = y_true[idx, :, target_idx]
        pred_vals = y_pred[idx, :, target_idx]
        
        ax.plot(x, true_vals, 'b-o', label='Actual', linewidth=2, markersize=5)
        ax.plot(x, pred_vals, 'r--s', label='Predicted', linewidth=2, markersize=5)
        
        # è®¡ç®—è¯¥æ ·æœ¬çš„è¯¯å·®
        mae = np.mean(np.abs(true_vals - pred_vals))
        
        ax.set_xlabel('Prediction Step (hours)', fontsize=11)
        ax.set_ylabel('Wind Speed (m/s)', fontsize=11)
        ax.set_title(f'Sample {idx} (MAE={mae:.3f} m/s)', fontsize=12)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.set_xticks(x)
    
    plt.suptitle(f'{model_name} - Multi-step Prediction (16h) - {TARGET_NAMES[target_idx]}', 
                fontsize=14, y=1.02)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"    âœ… ä¿å­˜: {os.path.basename(save_path)}")
    
    plt.close()


def plot_error_distribution(y_true, y_pred, model_name, task_name, save_path=None):
    """
    ç»˜åˆ¶é¢„æµ‹è¯¯å·®åˆ†å¸ƒå›¾
    """
    num_targets = y_true.shape[-1]
    fig, axes = plt.subplots(1, num_targets, figsize=(5*num_targets, 4))
    
    if num_targets == 1:
        axes = [axes]
    
    for i, (ax, name) in enumerate(zip(axes, TARGET_NAMES)):
        errors = (y_pred[:, :, i] - y_true[:, :, i]).flatten()
        
        ax.hist(errors, bins=50, density=True, alpha=0.7, color='steelblue', edgecolor='black')
        
        # ç»Ÿè®¡ä¿¡æ¯
        mu, std = errors.mean(), errors.std()
        
        # æ·»åŠ æ­£æ€åˆ†å¸ƒæ‹Ÿåˆæ›²çº¿
        from scipy import stats
        x = np.linspace(errors.min(), errors.max(), 100)
        ax.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2, 
               label=f'Normal\nÎ¼={mu:.3f}, Ïƒ={std:.3f}')
        
        ax.axvline(x=0, color='green', linestyle='--', linewidth=2, alpha=0.7)
        ax.set_xlabel('Prediction Error (m/s)', fontsize=11)
        ax.set_ylabel('Density', fontsize=11)
        ax.set_title(f'{name}', fontsize=12)
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3)
    
    plt.suptitle(f'{model_name} - {task_name} Error Distribution', fontsize=14, y=1.02)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"    âœ… ä¿å­˜: {os.path.basename(save_path)}")
    
    plt.close()


def generate_all_plots_for_model(model_name, task_type, test_loader, input_len, output_len):
    """ä¸ºå•ä¸ªæ¨¡å‹ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾"""
    task_name = 'Single-step (1h)' if task_type == 'singlestep' else 'Multi-step (16h)'
    task_suffix = 'singlestep' if task_type == 'singlestep' else 'multistep'
    
    print(f"\n  ğŸ“Š {model_name} - {task_name}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model(model_name, task_type, input_len, output_len)
    if model is None:
        return
    
    # è·å–é¢„æµ‹ç»“æœ
    try:
        y_true, y_pred = get_predictions(model, test_loader)
    except Exception as e:
        print(f"    âŒ é¢„æµ‹å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ¨¡å‹ä¸“å±ç›®å½•
    model_dir = os.path.join(PREDICTION_PLOTS_DIR, f'{model_name}_{task_suffix}')
    os.makedirs(model_dir, exist_ok=True)
    
    # 1. æ—¶åºå¯¹æ¯”å›¾
    plot_predictions_comparison(
        y_true, y_pred, model_name, task_name,
        save_path=os.path.join(model_dir, f'{model_name}_{task_suffix}_timeseries.png')
    )
    
    # 2. æ•£ç‚¹å›¾
    plot_scatter(
        y_true, y_pred, model_name, task_name,
        save_path=os.path.join(model_dir, f'{model_name}_{task_suffix}_scatter.png')
    )
    
    # 3. è¯¯å·®åˆ†å¸ƒå›¾
    plot_error_distribution(
        y_true, y_pred, model_name, task_name,
        save_path=os.path.join(model_dir, f'{model_name}_{task_suffix}_error_dist.png')
    )
    
    # 4. å¤šæ­¥é¢„æµ‹æ›²çº¿ï¼ˆä»…å¯¹å¤šæ­¥é¢„æµ‹ä»»åŠ¡ï¼‰
    if task_type == 'multistep' and y_true.shape[1] > 1:
        plot_multistep_curves(
            y_true, y_pred, model_name, target_idx=0,
            save_path=os.path.join(model_dir, f'{model_name}_multistep_curves_10m.png')
        )
        plot_multistep_curves(
            y_true, y_pred, model_name, target_idx=2,  # 100m
            save_path=os.path.join(model_dir, f'{model_name}_multistep_curves_100m.png')
        )


def generate_comparison_plot(all_results, task_type):
    """ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„å¯¹æ¯”å›¾"""
    task_name = 'Single-step' if task_type == 'singlestep' else 'Multi-step'
    
    if not all_results:
        return
    
    # å‡†å¤‡æ•°æ®
    models = list(all_results.keys())
    r2_scores = [all_results[m]['r2'] for m in models]
    rmse_scores = [all_results[m]['rmse'] for m in models]
    
    # æŒ‰RÂ²æ’åº
    sorted_idx = np.argsort(r2_scores)[::-1]
    models = [models[i] for i in sorted_idx]
    r2_scores = [r2_scores[i] for i in sorted_idx]
    rmse_scores = [rmse_scores[i] for i in sorted_idx]
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # RÂ² å¯¹æ¯”
    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(models)))
    bars1 = axes[0].barh(models, r2_scores, color=colors)
    axes[0].set_xlabel('RÂ²', fontsize=12)
    axes[0].set_title(f'{task_name} - RÂ² Comparison', fontsize=13)
    axes[0].grid(True, alpha=0.3, axis='x')
    for bar, val in zip(bars1, r2_scores):
        axes[0].text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.4f}', 
                    va='center', fontsize=9)
    
    # RMSE å¯¹æ¯”
    colors_rmse = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(models)))
    bars2 = axes[1].barh(models, rmse_scores, color=colors_rmse)
    axes[1].set_xlabel('RMSE (m/s)', fontsize=12)
    axes[1].set_title(f'{task_name} - RMSE Comparison', fontsize=13)
    axes[1].grid(True, alpha=0.3, axis='x')
    for bar, val in zip(bars2, rmse_scores):
        axes[1].text(val + 0.02, bar.get_y() + bar.get_height()/2, f'{val:.4f}', 
                    va='center', fontsize=9)
    
    plt.tight_layout()
    save_path = os.path.join(PREDICTION_PLOTS_DIR, f'all_models_comparison_{task_type}.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç”Ÿæˆæ¨¡å‹é¢„æµ‹ç»“æœå¯è§†åŒ–")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½æ•°æ®...")
    raw_df = load_all_data()
    processed_df = preprocess_data(raw_df)
    
    # å¤„ç†å•æ­¥é¢„æµ‹
    print("\n" + "=" * 60)
    print("å•æ­¥é¢„æµ‹ (8h â†’ 1h)")
    print("=" * 60)
    
    _, _, test_loader_single, _, _, _, _ = create_dataloaders(
        processed_df, input_len=SINGLE_STEP_INPUT_LEN, output_len=1, batch_size=64
    )
    
    single_results = {}
    for model_name in MODELS:
        model = load_model(model_name, 'singlestep', SINGLE_STEP_INPUT_LEN, 1)
        if model is not None:
            try:
                y_true, y_pred = get_predictions(model, test_loader_single)
                r2 = r2_score(y_true.flatten(), y_pred.flatten())
                rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))
                single_results[model_name] = {'r2': r2, 'rmse': rmse}
                generate_all_plots_for_model(model_name, 'singlestep', test_loader_single, 
                                            SINGLE_STEP_INPUT_LEN, 1)
            except Exception as e:
                print(f"  âŒ {model_name} å¤„ç†å¤±è´¥: {e}")
    
    generate_comparison_plot(single_results, 'singlestep')
    
    # å¤„ç†å¤šæ­¥é¢„æµ‹
    print("\n" + "=" * 60)
    print("å¤šæ­¥é¢„æµ‹ (8h â†’ 16h)")
    print("=" * 60)
    
    _, _, test_loader_multi, _, _, _, _ = create_dataloaders(
        processed_df, input_len=MULTI_STEP_INPUT_LEN, output_len=16, batch_size=64
    )
    
    multi_results = {}
    for model_name in MODELS:
        model = load_model(model_name, 'multistep', MULTI_STEP_INPUT_LEN, 16)
        if model is not None:
            try:
                y_true, y_pred = get_predictions(model, test_loader_multi)
                r2 = r2_score(y_true.flatten(), y_pred.flatten())
                rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))
                multi_results[model_name] = {'r2': r2, 'rmse': rmse}
                generate_all_plots_for_model(model_name, 'multistep', test_loader_multi,
                                            MULTI_STEP_INPUT_LEN, 16)
            except Exception as e:
                print(f"  âŒ {model_name} å¤„ç†å¤±è´¥: {e}")
    
    generate_comparison_plot(multi_results, 'multistep')
    
    print("\n" + "=" * 60)
    print(f"âœ… æ‰€æœ‰å¯è§†åŒ–å·²ä¿å­˜åˆ°: {PREDICTION_PLOTS_DIR}")
    print("=" * 60)


if __name__ == '__main__':
    main()
